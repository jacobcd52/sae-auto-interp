{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"/root/sae-auto-interp\")\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from functools import partial\n",
    "\n",
    "from sae_auto_interp.features import FeatureDataset, FeatureCache, pool_max_activation_windows, sample\n",
    "from sae_auto_interp.config import FeatureConfig, ExperimentConfig\n",
    "from sae_auto_interp.get_activations import get_activations\n",
    "from sae_auto_interp.utils import load_tokenized_data, display\n",
    "from sae_auto_interp.clients import OpenRouter\n",
    "from sae_auto_interp.explainers import SimpleExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "N_TOKENS = 1_000_000\n",
    "MODEL_NAME = \"google/gemma-2b-it\"\n",
    "DATASET_NAME = \"jacobcd52/college_math_cleaned\"\n",
    "DATASET_SPLIT = \"train\"\n",
    "FEATURE_IDX_LIST = list(range(100))\n",
    "SAE_REPO = \"jacobcd52/gemma-2b-it-ssae-college_math_cleaned\"\n",
    "SAE_CFG_FILE = \"gemma-2b-it_layer12_college_math_cleaned_l1=10_expansion=2_tokens=8192000_gsae_id=layer_12_stepan_cfg.json\"\n",
    "SAE_WEIGHTS_FILE = \"gemma-2b-it_layer12_college_math_cleaned_l1=10_expansion=2_tokens=8192000_gsae_id=layer_12_stepan.safetensors\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc8be202f9d4715aa4d3a7ceb2491f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3473e08cb76b4b01853920b6f78b9cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)8192000_gsae_id=layer_12_stepan_cfg.json:   0%|          | 0.00/2.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module path .model.layers.12\n",
      "dict_keys(['.model.layers.12'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching features:   0%|          | 0/244 [00:00<?, ?it/s]You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Caching features: 100%|██████████| 244/244 [05:11<00:00,  1.28s/it, Total Tokens=999,424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens processed: 999,424\n",
      "saving split at  /root/sae-auto-interp/splits/.model.layers.12\n",
      "saving split at  /root/sae-auto-interp/splits/.model.layers.12\n",
      "saving split at  /root/sae-auto-interp/splits/.model.layers.12\n",
      "saving split at  /root/sae-auto-interp/splits/.model.layers.12\n",
      "saving split at  /root/sae-auto-interp/splits/.model.layers.12\n"
     ]
    }
   ],
   "source": [
    "# Run model to get SAE feature activations\n",
    "model, sae_width = get_activations(sae_repo = SAE_REPO,\n",
    "                    sae_weights_file = SAE_WEIGHTS_FILE,\n",
    "                    sae_cfg_file = SAE_CFG_FILE,\n",
    "                    feature_idx_list = FEATURE_IDX_LIST,\n",
    "                    dataset_name  = DATASET_NAME,\n",
    "                    dataset_split = DATASET_SPLIT,\n",
    "                    model_name = MODEL_NAME,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    ctx_len = CTX_LEN,\n",
    "                    n_tokens = N_TOKENS,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading .model.layers.12: 814it [01:05, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of records 623\n",
      "first feature: .model.layers.12_feature0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       ", 469, 539, 543, 545, 554, 567 exponential<mark><bos></mark> notation 6, 66 extraneous<br><br> H and H is not a That is, s D vector space. 1<mark>v</mark>1 2<mark><bos></mark>. v1 0v2 D D v1; : : : ;<mark> vp</mark>, so<br><br>_1, ’2π 3 ”_ œ„, ’3π 42 ”_ œ„, ’5π 63 FIGURE 8 Table<mark><bos></mark> of values and graph of<br><br><mark><bos></mark> so large t<mark><bos></mark>hat if n ≥ N and t ∈ f (t) | [a, L0]. This is possible because fn → fn(t) − | < L0 ∞"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = FeatureConfig(\n",
    "    width = sae_width,\n",
    "    min_examples = 200,\n",
    "    max_examples = 10_000,\n",
    "    example_ctx_len = 40,\n",
    "    n_splits = 5\n",
    ")\n",
    "\n",
    "experiment_cfg = ExperimentConfig(n_quantiles=2) # TODO change?\n",
    "\n",
    "feature_dataset = FeatureDataset(\n",
    "    raw_dir=\"/root/sae-auto-interp/splits\",\n",
    "    cfg=cfg,\n",
    ")\n",
    "\n",
    "tokens = load_tokenized_data(\n",
    "    CTX_LEN,\n",
    "    model.tokenizer,\n",
    "    DATASET_NAME,\n",
    "    DATASET_SPLIT)\n",
    "\n",
    "constructor=partial(\n",
    "    pool_max_activation_windows,\n",
    "    tokens=tokens,\n",
    "    ctx_len=cfg.example_ctx_len,\n",
    "    max_examples=cfg.max_examples,\n",
    ")\n",
    "\n",
    "sampler = partial(\n",
    "    sample,\n",
    "    cfg=experiment_cfg\n",
    ")\n",
    "\n",
    "loaded_data_iter = iter(feature_dataset.load(constructor=constructor, sampler=sampler))\n",
    "records = next(loaded_data_iter)\n",
    "\n",
    "print(\"length of records\", len(records))\n",
    "print(\"first feature:\", records[0].feature)\n",
    "display(records[0], model.tokenizer, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " radius 1, so its area is p, and the square has area 4. If we choose a point at random from the square<mark>, the</mark> probability that it lies inside the circle will be area<br><br> 2 minutes? 18. In rolling one die<mark> repeatedly, what</mark> is<mark> the</mark> probability<mark> of getting the</mark> third six on the xth<mark> roll</mark>? 19. A coin is tossed 6<mark> times</mark><br><br> balls are randomly<mark> drawn</mark> from the<mark> urn with replacement. Use</mark> the appropriate Poisson distribution to approximate the probability<mark> that</mark> ﬁve black balls are observed. 2.3.20 Suppose that there is a loop<br><br><mark> coin,</mark> heads and tails are equally likely outcomes in the sense that if this experiment is<mark> repeated many times, we</mark> expect<mark> that</mark> about as many heads as tails will show up. In any given experiment we are<br><br> certain virus afflicted the families in 3 adjacent houses in a row of 12 houses. If three houses were randomly chosen from a row of 12 houses<mark>, what is the</mark> probability<mark> that</mark> the<br><br> initiative. If ﬁve voters are interviewed at random<mark>, what is the</mark> probability<mark> that</mark> exactly three of them will favor the initiative? 29. Pharmaceuticals A drug that is used to prevent motion sickness is<br><br>3, has minimum variance? 12. A box contains 5 white balls and 3 black balls<mark>.</mark> Draw<mark> 2 balls without replacement. If</mark> X represents<mark> the</mark> number of white balls and Y<br><br> FI GUR E 4. 10 The complement of an event ● A∪B Ac A S S EXAMPLE 4.16 Two fair coins are<mark> tossed, and the outcome is</mark> recorded<mark>.</mark><br><br> the United States are reported as.41,.10,.04, and.45, respectively.1 If a single Caucasian is chosen randomly from the population<mark>, what is the</mark> probability that<br><br><mark>, what</mark> is the probability that it lies in the span of some other vectors?” i. Given a collection S of k bit vectors in B3, consider the bit matrix M whose columns are the vectors"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron activates at the beginning of sentences in mathematical or scientific texts, potentially helping to structure technical content.\n"
     ]
    }
   ],
   "source": [
    "client = OpenRouter('anthropic/claude-3.5-sonnet', api_key=\"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\")\n",
    "explainer = SimpleExplainer(\n",
    "    client,\n",
    "    model.tokenizer,\n",
    "    max_new_tokens=50,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "explainer_result = await explainer(records[3])\n",
    "display(records[3], model.tokenizer)\n",
    "print(explainer_result.explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<mark><bos></mark> used natural logarithms instead of common logarithms. In fact, using the same steps, we get <mark><bos></mark>x ln 7 ln 3 2 0.228756 <br><br><mark><bos></mark> so large t<mark><bos></mark>hat if n ≥ N and t ∈ f (t) | [a, L0]. This is possible because fn → fn(t) − | < L0 ∞<br><br><mark><bos></mark> compact sets each contained in an open Rn ⊂ M. By inductio<mark><bos></mark>n on m this gives a reduction to the case m = 1, so A ⊂ Rn ⊂ M<br><br><mark><bos></mark> remaining vectors will be linearly independent and will still span S. In other from words, the remaining vectors will be a basis for S. We use the casting-out algorithm to identity t<mark><bos></mark>he<br><br><mark><bos></mark> Rates Suppose we have two variables x <mark><bos></mark>and y (in most problems the letters will be diﬀerent, but for now let’s use x and y) which are both changing with<br><br><mark><bos></mark> current section. In the next section, we will see how the zeros of give us an exact formula for J; then we will finally plug J back into the <mark><bos></mark>Moebius-inverted<br><br><mark><bos></mark> contributes no more <mark><bos></mark>than ωf ([xk 1, xk])(xk − − xk 1) − Xk=1 while the latter sum contributes no more than (2M<br><br><mark><bos></mark> in presenting a formal axiomatic theory is how to specify the system of logic to be used. One obvious way is to give the rules of inference. In all <mark><bos></mark>interesting systems the set of<br><br><mark><bos></mark> F is clearly isomorphic to gp({di liE I}). But ~ Q i is divisible since each Qi is divisible. The result follows. i E I (b) If G is any group<br><br><mark><bos></mark> of the negative differences and reject the null hypothesis for small values of T —say, T T0. If you wish to detect a shift of distribution 2 to the right of distribution 1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(records[5], model.tokenizer, n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
